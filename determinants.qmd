---
title: "Determinants"
execute:
  echo: false
---

::: {.callout-tip appearance="simple"}
## Video

[10 properties](https://youtu.be/XpHWtYALXOE)
:::

Determinant of a square $n\times n$ matrix is a special number we assign to the matrix and on which many other properties of it lie. It is a useful definition.

Rather than giving a formula for the calculation, lets list its properties that this formula would have:

1.  Determinant of the identity is $1$:

    $$
    \det I = 1
    $$

    Example:

    $$
    \left|\begin{matrix}1 & 0\\ 0 & 1 \end{matrix}\right|=1
    $$

2.  Exchange rows of the matrix: flip the sign of the determinant.

    Example:

    $$
    \left|\begin{matrix}0 & 1\\ 1 & 0 \end{matrix}\right|=-1
    $$

3.  The determinant is row-wise linear.

    Example:

    $$
    \left|\begin{matrix}3 a & 3 b\\ c & d \end{matrix}\right| = 3\left|\begin{matrix}a & b\\ c & d \end{matrix}\right| = \left|\begin{matrix}a & b\\ 3c & 3d \end{matrix}\right|
    $$

    and

    $$
    \left|\begin{matrix}a +5 & b+5\\ c & d \end{matrix}\right| = \left|\begin{matrix}a & b\\ c & d \end{matrix}\right| + \left|\begin{matrix}5 & 5\\  c & d \end{matrix}\right|
    $$

    *Warning:* this last expression tells us that:

    $$
    \left|\begin{matrix}a +a' & b+b'\\ c+c' & d+d' \end{matrix}\right| \not= \left|\begin{matrix}a & b\\ c & d \end{matrix}\right| + \left|\begin{matrix}a' & b'\\  c' & d' \end{matrix}\right|
    $$

    which put into English, just says the determinant is NOT linear in both rows simultaneously.

4.  If two rows of the matrix are equal, then the determinant is $0$.

    *Justification:* On the rhs of the following equality we find the matrix of the lhs with last two rows flipped, since these two rows are equal the matrix stays the same, so the determinant must be the same:

    $$
    \left|\begin{matrix}3 & 3 & 3\\ 2 & 2 & 4\\2 & 2 & 4\end{matrix}\right|=\left|\begin{matrix}3 & 3 & 3\\ 2 & 2 & 4\\2 & 2 & 4\end{matrix}\right|
    $$

    However, by rule 2. the sign must change, i.e.,

    $$
    \left|\begin{matrix}3 & 3 & 3\\ 2 & 2 & 4\\2 & 2 & 4\end{matrix}\right|=-\left|\begin{matrix}3 & 3 & 3\\ 2 & 2 & 4\\2 & 2 & 4\end{matrix}\right|
    $$

    What number satisfies these two conditions? Answer: $0$.

5.  Linear combination of rows does not change the $\det$

    For example:

    $$
    \left|\begin{matrix}a & b\\ c-2a & d-2b \end{matrix}\right| = \left|\begin{matrix}a & b\\ c & d \end{matrix}\right| + \left|\begin{matrix}a & b\\  -2a & -2b \end{matrix}\right|=\left|\begin{matrix}a & b\\ c & d \end{matrix}\right| -2 \left|\begin{matrix}a & b\\  a & b \end{matrix}\right|
    $$

    The second determinant is zero, since the two rows are equal.

    ::: callout-warning
    ## Warning

    l.c. of rows, multiplying a row by a number or flipping rows are operation used in elimination which lead to equivalent systems of equations. However, as we see from rule 2. and 3., the determinant changes, only l.c. of rows keeps the determinant!
    :::

6.  A row of zeros, mean the $\det$ is zero.

    *Justification:* Using row-wise linearity we find

    $$
    \left|\begin{matrix}a & b\\ 0 & 0 \end{matrix}\right| = \left|\begin{matrix}a & b\\ 0\cdot c & 0\cdot d \end{matrix}\right| = 0\left|\begin{matrix}a & b\\ c & d \end{matrix}\right|=0
    $$

7.  The determinant of a upper (lower) triangular matrix is the product of the diagonal.

    Example:

    $$
    \left|\begin{matrix}3 & 3 & 3\\ 0 & 2 & 4\\0 & 0 & 1\end{matrix}\right|=3\cdot 2 \cdot 1
    $$

    *Justification:*

    $$
    \left|\begin{matrix}3 & 3 & 3\\ 0 & 2 & 4\\0 & 0 & 1\end{matrix}\right| =  \left|\begin{matrix}3 & 0 & 0\\ 0 & 2 & 0\\0 & 0 & 1\end{matrix}\right| = 3\cdot 2\cdot 1\left|\begin{matrix}1 & 0 & 0\\ 0 & 1 & 0\\0 & 0 & 1\end{matrix}\right| =3\cdot 2\cdot 1
    $$

    In the first step we used l.c. to eliminate the entries above the pivots, on the second step we used the row-wise linearity to pull out the diagonal leaving us the determinant of the identity which is just $1$.

8.  When a matrix has dependent rows, then its $\det A = 0$.

    *Justification:* Let $A$ be $3\times 3$, and imagine the last row is the sum of the first two, then through l.c. of rows we can eliminate all entries in the last row, which means by rule 6, the determinate is zero.

9.  Determinant of a product is the product of determinants.

    $$
    \det AB =\det A \times \det B
    $$

10. Transpose does not affect the value of the determinant:

    $$
    \det A^\intercal =\det A
    $$

    *Consequence:* If two columns are dependent, then the determinant is zero.

# Using determinant properties to compute determinants

::: {.callout-tip appearance="simple"}
## Video

[Determinant of a 2 by 2 and 3 by 3 matrix](https://youtu.be/l4tSYsJLNG0)
:::

We still do not have a formula for the calculation of the determinant, but the rules above were provided, and are sufficient, to do the task; they work by breaking the original determinant into small and computable pieces.

## Determinant of a $2\times 2$ matrix:

$$
\begin{align}
\left|\begin{matrix} a &  b\\ c & d \end{matrix}\right| &=
 \left|\begin{matrix} a +0  &  b+0\\ c & d \end{matrix}\right|=
 \left|\begin{matrix}a & 0\\ c & d \end{matrix}\right|+\left|\begin{matrix}0 & b\\ c & d \end{matrix}\right|\\
&=\left|\begin{matrix}a & 0\\ c+0 & d+0 \end{matrix}\right|+\left|\begin{matrix}0 & b\\ c+0 & d+0 \end{matrix}\right|\\
&=\left|\begin{matrix}a & 0\\ 0 & d \end{matrix}\right|+\left|\begin{matrix}a & 0\\ c & 0 \end{matrix}\right|+\left|\begin{matrix}0 & b\\ 0 & d \end{matrix}\right|+\left|\begin{matrix}0 & b\\ c & 0\end{matrix}\right|\\
&=\left|\begin{matrix}a & 0\\ 0 & d \end{matrix}\right|+\left|\begin{matrix}0 & b\\ c & 0\end{matrix}\right|\\
&=ad-bc
\end{align}
$$

*Important obs:* We can use the properties of determinant to make every entry of the first row zero except one

$$
\left|\begin{matrix}a & 0\\ c & d \end{matrix}\right|+\left|\begin{matrix}0 & b\\ c & d \end{matrix}\right|
$$

and then do the same in the second row. However, in doing that remember that columns of zeros yield zero determinants, thus the nonzero entry on the second row must be put away of the column on which the nonzero is on the first row. Another way to put this: once we choose a nonzero entry in the first row, we make the remainder of the row entries and column entries all zero.

## Determinant of a $3\times 3$ matrix

Inspired by the observation above we put zeros on the row of column of the nonzero entry of the first row:

$$
\begin{align}\left|\begin{matrix} A_{11} &  A_{12} & A_{13}\\ A_{21} & A_{22} & A_{23}\\A_{31} & A_{32} & A_{33} \end{matrix}\right| &= \left|\begin{matrix} A_{11} &  0 & 0\\ 0 & A_{22} & A_{23}\\0 & A_{32} & A_{33} \end{matrix}\right|+ \left|\begin{matrix} 0 &  A_{12} & 0\\ A_{21} & 0 & A_{23}\\A_{31} & 0 & A_{33} \end{matrix}\right|+ \left|\begin{matrix} 0 &  0 & A_{13}\\ A_{21} & A_{22} & 0\\A_{31} & A_{32} &0 \end{matrix}\right|
\end{align}
$$

Then do the same in the second row:

$$
\left|\begin{matrix} A_{11} &  0 & 0\\ 0 & A_{22} & A_{23}\\0 & A_{32} & A_{33} \end{matrix}\right| = \left|\begin{matrix} A_{11} &  0 & 0\\ 0 & A_{22} & 0\\0 & 0 & A_{33} \end{matrix}\right| + \left|\begin{matrix} A_{11} &  0 & 0\\ 0 & 0 & A_{23}\\0 & A_{32} & 0 \end{matrix}\right|=A_{11}(A_{22}A_{33}-A_{23}A_{32}) =A_{11}
\left|\begin{matrix}A_{22} & A_{23}\\ A_{32} & A_{33} \end{matrix}\right|
$$

$$
\left|\begin{matrix} 0 &  A_{12} & 0\\ A_{21} & 0 & A_{23}\\A_{31} & 0 & A_{33} \end{matrix}\right|=\left|\begin{matrix} 0 &  A_{12} & 0\\ A_{21} & 0 & 0\\0 & 0 & A_{33} \end{matrix}\right|+\left|\begin{matrix} 0 &  A_{12} & 0\\ 0 & 0 & A_{23}\\A_{31} & 0 & 0 \end{matrix}\right|=-A_{12}(A_{21}A_{33}-A_{23}A_{31})=-A_{12}\left|\begin{matrix}A_{21} & A_{23}\\ A_{31} & A_{33} \end{matrix}\right|
$$

$$
\left|\begin{matrix} 0 &  0 & A_{13}\\ A_{21} & A_{22} & 0\\A_{31} & A_{32} &0 \end{matrix}\right|= \left|\begin{matrix} 0 &  0 & A_{13}\\ 0 & A_{22} & 0\\A_{31} & 0 &0 \end{matrix}\right|+\left|\begin{matrix} 0 &  0 & A_{13}\\ A_{21} & 0 & 0\\0 & A_{32} &0 \end{matrix}\right|=A_{13}(A_{21}A_{32}-A_{22}A_{31}) =A_{13}\left|\begin{matrix}A_{21} & A_{22}\\ A_{31} & A_{32} \end{matrix}\right|
$$

We conclude that:

$$
\det A = A_{11}\left|\begin{matrix}A_{22} & A_{23}\\ A_{32} & A_{33} \end{matrix}\right|-A_{12}\left|\begin{matrix}A_{21} & A_{23}\\ A_{31} & A_{33} \end{matrix}\right|+A_{13}\left|\begin{matrix}A_{21} & A_{22}\\ A_{31} & A_{32} \end{matrix}\right|
$$

## General formula to compute determinants

From the rhs of these calculation we name $A_{11}$, $A_{12}$ and $A_{13}$ the factors and the corresponding subdeterminants the cofactors

$$
[\text{cofactor of}\,A_{ij}]=C_{ij} = (-1)^{i+j}\det(\text{matrix with row}\,i\,\text{and column}\,j\,\text{supressed})
$$

The funny term $(-1)^{i+j}$ just tracks the sign of the permutation we did above, note the $-\left|\begin{matrix}A_{21} & A_{23}\\ A_{31} & A_{33} \end{matrix}\right|$ above.

It is easy to identify these signs if we remember $(-1)^{i+j}$ are the form of entries of the following matrix:

$$
\left(\begin{matrix} + &  - & +\\ - & + & -\\+ & - & + \end{matrix}\right)
$$

Thus the general formula to compute determinants of square $n\times n$ matrices is:

$$
\det A = A_{11} C_{11} + A_{12} C_{12}+\dots+A_{1n}C_{1n}
$$

With it we can write an important equality that will be useful when we introduce inverse matrices:

$$
\left(\begin{matrix} A_{11} &  A_{12} & A_{13}\\ A_{21} & A_{22} & A_{23}\\ A_{31} & A_{32} & A_{33} \end{matrix}\right) \left(\begin{matrix} C_{11} &  C_{21} & C_{31}\\ C_{12} & C_{22} & C_{32}\\ C_{13} & C_{23} & C_{33} \end{matrix}\right)=\left(\begin{matrix} \det A &  0 & 0\\ 0 & \det A & 0\\ 0 & 0 & \det A \end{matrix}\right)
$$

In compact form:

$$
AC^\intercal =I\det A
$$

# Determinants define volumes

Here is a fact about the meaning of determinant of a matrix:

$$
\det \left(\begin{matrix} A_{11} &  A_{12} & A_{13}\\ A_{21} & A_{22} & A_{23}\\ A_{31} & A_{32} & A_{33} \end{matrix}\right) = [\text{signed volume of columns}] = [\text{signed volume of rows}]
$$

We'll not prove this fact but give three clues that make it seem reasonable:

-   If one column (or row) is dependent, then as expected, the volume is zero and correspondingly the determinant is zero as well by rule 8.

-   The determinant of the identity is $1$, as expected by a cube of side $1$. Since the columns of $A$ are essentially $A\mathbf{e}_i$, we would expect that $\det A$ is the volume encapsulated within the columns.

-   Flipping rows, only changes the sign of the determinant. but not its absolute value. The sign has to do with the order in which the columns (or rows) appear in $A$.
